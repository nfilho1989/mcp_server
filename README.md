# MCP + Elasticsearch + LangChain Demo

Este projeto demonstra a integraÃ§Ã£o entre Model Context Protocol (MCP), Elasticsearch e LangChain para criar um sistema de RAG (Retrieval-Augmented Generation).

## ğŸš€ Como executar

### 1. Acessar o container

```bash
docker exec -it mcp-elasticsearch-server /bin/bash
```

### 2. Executar o aplicativo principal

```bash
cd /app
python src/init_app.py
```

### 3. OpÃ§Ãµes disponÃ­veis

1. **Testar Elasticsearch**: Verifica se a conexÃ£o e busca estÃ£o funcionando
2. **Iniciar servidor MCP**: Inicia o servidor MCP (ainda nÃ£o conectado ao agente)
3. **Iniciar agente de IA**: Chat interativo com o assistente
4. **Exemplo completo**: DemonstraÃ§Ã£o de todas as funcionalidades
5. **Limpar dados**: Remove todos os dados do Ã­ndice

## ğŸ“ Exemplos de perguntas para o agente

- "Quais posts existem sobre usuÃ¡rios?"
- "Me mostre os posts mais recentes"
- "Quantos documentos existem por categoria?"
- "Busque posts que mencionam email"
- "Me dÃª detalhes do post com ID post_1"

## ğŸ› ï¸ Instalando Ollama (para o modelo LLM gratuito)

Para usar o agente de IA, vocÃª precisa instalar o Ollama no container:

```bash
# Dentro do container
curl -fsSL https://ollama.ai/install.sh | sh

# Baixar o modelo Llama2 (ou mistral para algo menor)
ollama pull llama2
# ou
ollama pull mistral

# Iniciar o servidor Ollama em background
ollama serve &
```

## ğŸ“Š Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚     â”‚                  â”‚     â”‚               â”‚
â”‚  LangChain      â”‚â”€â”€â”€â”€â–¶â”‚  MCP Server      â”‚â”€â”€â”€â”€â–¶â”‚ Elasticsearch â”‚
â”‚  Agent          â”‚     â”‚                  â”‚     â”‚               â”‚
â”‚                 â”‚     â”‚                  â”‚     â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                                 â”‚
        â”‚                                                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    Direct ES Access (for now)
```

## ğŸ”§ Estrutura do Projeto

```
/app/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ mcp_server/
â”‚   â”‚   â”œâ”€â”€ mcp_config.json
â”‚   â”‚   â””â”€â”€ server.py
â”‚   â”œâ”€â”€ elasticsearch_client/
â”‚   â”‚   â””â”€â”€ es_client.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ elasticsearch_agent.py
â”‚   â””â”€â”€ init_app.py
â”œâ”€â”€ data/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env
```

## ğŸ› Troubleshooting

**Problema**: Elasticsearch nÃ£o conecta
- SoluÃ§Ã£o: Verifique se o container estÃ¡ rodando: `docker ps`

**Problema**: Ollama nÃ£o funciona
- SoluÃ§Ã£o: Instale e inicie o Ollama conforme instruÃ§Ãµes acima

**Problema**: Agente nÃ£o responde
- SoluÃ§Ã£o: Verifique se o modelo foi baixado: `ollama list`
